2019-06-22 02:48:25,166 - [org.apache.spark.internal.Logging$class.logError(Logging.scala:91)] ERROR [org.apache.spark.executor.Executor] - Exception in task 1.0 in stage 1.0 (TID 2)
java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:173)
	at org.apache.spark.sql.Row$class.getAs(Row.scala:322)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:165)
	at org.apache.spark.sql.Row$class.getString(Row.scala:255)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getString(rows.scala:165)
	at com.qf.ads_put.etl.getuser.ods.OdsLoadSourceData$$anonfun$main$1.apply(OdsLoadSourceData.scala:37)
	at com.qf.ads_put.etl.getuser.ods.OdsLoadSourceData$$anonfun$main$1.apply(OdsLoadSourceData.scala:36)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:926)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:926)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-22 02:48:25,243 - [org.apache.spark.internal.Logging$class.logError(Logging.scala:70)] ERROR [org.apache.spark.scheduler.TaskSetManager] - Task 1 in stage 1.0 failed 1 times; aborting job
2019-06-22 03:14:27,532 - [org.apache.spark.internal.Logging$class.logError(Logging.scala:91)] ERROR [org.apache.spark.executor.Executor] - Exception in task 1.0 in stage 1.0 (TID 2)
scala.MatchError: Map(latitude -> 40.06654, aid -> 1002, matter_id -> M7, area_code -> 110114, longitude -> 116.38734, idcard -> 110109198206252596, model_version -> V9, model_code -> ML8) (of class scala.collection.immutable.HashMap$HashTrieMap)
	at com.qf.ads_put.etl.getuser.ods.OdsLoadSourceData$$anonfun$2.apply(OdsLoadSourceData.scala:37)
	at com.qf.ads_put.etl.getuser.ods.OdsLoadSourceData$$anonfun$2.apply(OdsLoadSourceData.scala:36)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:926)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:926)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-22 03:14:27,548 - [org.apache.spark.internal.Logging$class.logError(Logging.scala:70)] ERROR [org.apache.spark.scheduler.TaskSetManager] - Task 1 in stage 1.0 failed 1 times; aborting job
2019-06-22 03:32:00,988 - [org.apache.spark.internal.Logging$class.logError(Logging.scala:91)] ERROR [org.apache.spark.executor.Executor] - Exception in task 1.0 in stage 1.0 (TID 2)
scala.MatchError: Map(latitude -> 40.06654, aid -> 1002, matter_id -> M7, area_code -> 110114, longitude -> 116.38734, idcard -> 110109198206252596, model_version -> V9, model_code -> ML8) (of class scala.collection.immutable.HashMap$HashTrieMap)
	at com.qf.ads_put.etl.getuser.ods.OdsLoadSourceData$$anonfun$2.apply(OdsLoadSourceData.scala:38)
	at com.qf.ads_put.etl.getuser.ods.OdsLoadSourceData$$anonfun$2.apply(OdsLoadSourceData.scala:37)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:926)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:926)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-22 03:32:01,008 - [org.apache.spark.internal.Logging$class.logError(Logging.scala:70)] ERROR [org.apache.spark.scheduler.TaskSetManager] - Task 1 in stage 1.0 failed 1 times; aborting job
